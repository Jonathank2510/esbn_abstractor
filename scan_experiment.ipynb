{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathankonig/miniforge3/envs/esbn_abstractor/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from Models.Transformers import Transformer, ESBNTransformer, ESBNTransformerSCA\n",
    "from Utils.preprocess_scan import generate_data\n",
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we compare two variants of integrating the esbn into a transformer against the standard transformer. The code for the transformer is adapted from the tensorflow blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 19:40:51.760034: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Generate data and get vocab sizes\n",
    "train_ds, val_ds, command_vocab_len, action_vocab_len = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "458/458 [==============================] - 22s 40ms/step - loss: 0.8136 - masked_accuracy: 0.6780 - val_loss: 2.8789 - val_masked_accuracy: 0.4229\n",
      "Epoch 2/20\n",
      "458/458 [==============================] - 17s 36ms/step - loss: 0.5087 - masked_accuracy: 0.7769 - val_loss: 3.0768 - val_masked_accuracy: 0.4735\n",
      "Epoch 3/20\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.4339 - masked_accuracy: 0.8051 - val_loss: 3.1229 - val_masked_accuracy: 0.5073\n",
      "Epoch 4/20\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.3477 - masked_accuracy: 0.8513 - val_loss: 3.2294 - val_masked_accuracy: 0.5464\n",
      "Epoch 5/20\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.2415 - masked_accuracy: 0.8989 - val_loss: 3.3636 - val_masked_accuracy: 0.5602\n",
      "Epoch 6/20\n",
      "458/458 [==============================] - 18s 40ms/step - loss: 0.1976 - masked_accuracy: 0.9181 - val_loss: 3.5235 - val_masked_accuracy: 0.5514\n",
      "Epoch 7/20\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.1620 - masked_accuracy: 0.9323 - val_loss: 3.4649 - val_masked_accuracy: 0.5655\n",
      "Epoch 8/20\n",
      "458/458 [==============================] - 18s 38ms/step - loss: 0.1379 - masked_accuracy: 0.9431 - val_loss: 3.3041 - val_masked_accuracy: 0.5836\n",
      "Epoch 9/20\n",
      "458/458 [==============================] - 18s 40ms/step - loss: 0.1192 - masked_accuracy: 0.9518 - val_loss: 3.6777 - val_masked_accuracy: 0.5970\n",
      "Epoch 10/20\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.1074 - masked_accuracy: 0.9561 - val_loss: 3.3071 - val_masked_accuracy: 0.6195\n",
      "Epoch 11/20\n",
      "458/458 [==============================] - 18s 38ms/step - loss: 0.0927 - masked_accuracy: 0.9630 - val_loss: 3.3486 - val_masked_accuracy: 0.6351\n",
      "Epoch 12/20\n",
      "458/458 [==============================] - 19s 41ms/step - loss: 0.0899 - masked_accuracy: 0.9642 - val_loss: 3.4049 - val_masked_accuracy: 0.6304\n",
      "Epoch 13/20\n",
      "458/458 [==============================] - 17s 37ms/step - loss: 0.0837 - masked_accuracy: 0.9665 - val_loss: 3.5940 - val_masked_accuracy: 0.6325\n",
      "Epoch 14/20\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.0724 - masked_accuracy: 0.9711 - val_loss: 3.4880 - val_masked_accuracy: 0.6335\n",
      "Epoch 15/20\n",
      "458/458 [==============================] - 18s 39ms/step - loss: 0.0665 - masked_accuracy: 0.9738 - val_loss: 3.4288 - val_masked_accuracy: 0.6582\n",
      "Epoch 16/20\n",
      "458/458 [==============================] - 17s 38ms/step - loss: 0.0671 - masked_accuracy: 0.9736 - val_loss: 3.5386 - val_masked_accuracy: 0.6439\n",
      "Epoch 17/20\n",
      "458/458 [==============================] - 19s 41ms/step - loss: 0.0623 - masked_accuracy: 0.9756 - val_loss: 4.0176 - val_masked_accuracy: 0.6020\n",
      "Epoch 18/20\n",
      "458/458 [==============================] - 17s 38ms/step - loss: 0.0563 - masked_accuracy: 0.9782 - val_loss: 3.9635 - val_masked_accuracy: 0.6262\n",
      "Epoch 19/20\n",
      "458/458 [==============================] - 19s 42ms/step - loss: 0.0545 - masked_accuracy: 0.9793 - val_loss: 4.0076 - val_masked_accuracy: 0.6083\n",
      "Epoch 20/20\n",
      "458/458 [==============================] - 17s 38ms/step - loss: 0.0548 - masked_accuracy: 0.9787 - val_loss: 4.1604 - val_masked_accuracy: 0.6237\n",
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  42784     \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  76288     \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,402\n",
      "Trainable params: 119,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Ordinary Transformer\n",
    "num_layers = 2\n",
    "d_model = 32\n",
    "dff = 64\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=command_vocab_len,\n",
    "    target_vocab_size=action_vocab_len,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "log_dir = \"logs/fit/scan_transformer/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "transformer.fit(train_ds,\n",
    "                epochs=20,\n",
    "                validation_data=val_ds,\n",
    "                callbacks=[tensorboard_callback])\n",
    "\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "458/458 [==============================] - 35s 60ms/step - loss: 0.8085 - masked_accuracy: 0.6803 - val_loss: 2.7810 - val_masked_accuracy: 0.4616\n",
      "Epoch 2/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.5051 - masked_accuracy: 0.7820 - val_loss: 2.8242 - val_masked_accuracy: 0.4950\n",
      "Epoch 3/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.3575 - masked_accuracy: 0.8517 - val_loss: 2.7274 - val_masked_accuracy: 0.5765\n",
      "Epoch 4/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.2430 - masked_accuracy: 0.9009 - val_loss: 2.7162 - val_masked_accuracy: 0.5822\n",
      "Epoch 5/20\n",
      "458/458 [==============================] - 29s 63ms/step - loss: 0.1899 - masked_accuracy: 0.9233 - val_loss: 2.5777 - val_masked_accuracy: 0.6329\n",
      "Epoch 6/20\n",
      "458/458 [==============================] - 29s 63ms/step - loss: 0.1551 - masked_accuracy: 0.9376 - val_loss: 2.8128 - val_masked_accuracy: 0.6479\n",
      "Epoch 7/20\n",
      "458/458 [==============================] - 29s 64ms/step - loss: 0.1302 - masked_accuracy: 0.9473 - val_loss: 3.0657 - val_masked_accuracy: 0.6427\n",
      "Epoch 8/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.1079 - masked_accuracy: 0.9570 - val_loss: 3.4429 - val_masked_accuracy: 0.5879\n",
      "Epoch 9/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.0974 - masked_accuracy: 0.9616 - val_loss: 3.7750 - val_masked_accuracy: 0.5924\n",
      "Epoch 10/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0846 - masked_accuracy: 0.9669 - val_loss: 3.7803 - val_masked_accuracy: 0.6024\n",
      "Epoch 11/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.0806 - masked_accuracy: 0.9689 - val_loss: 3.6171 - val_masked_accuracy: 0.6011\n",
      "Epoch 12/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0694 - masked_accuracy: 0.9732 - val_loss: 3.8463 - val_masked_accuracy: 0.5972\n",
      "Epoch 13/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.0661 - masked_accuracy: 0.9745 - val_loss: 3.3932 - val_masked_accuracy: 0.6238\n",
      "Epoch 14/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0692 - masked_accuracy: 0.9738 - val_loss: 4.0939 - val_masked_accuracy: 0.5872\n",
      "Epoch 15/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0562 - masked_accuracy: 0.9788 - val_loss: 4.1837 - val_masked_accuracy: 0.5932\n",
      "Epoch 16/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.0552 - masked_accuracy: 0.9791 - val_loss: 4.0588 - val_masked_accuracy: 0.6093\n",
      "Epoch 17/20\n",
      "458/458 [==============================] - 29s 63ms/step - loss: 0.0563 - masked_accuracy: 0.9786 - val_loss: 4.0727 - val_masked_accuracy: 0.6111\n",
      "Epoch 18/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0503 - masked_accuracy: 0.9811 - val_loss: 3.9142 - val_masked_accuracy: 0.5881\n",
      "Epoch 19/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0475 - masked_accuracy: 0.9821 - val_loss: 3.6803 - val_masked_accuracy: 0.6218\n",
      "Epoch 20/20\n",
      "458/458 [==============================] - 28s 62ms/step - loss: 0.0449 - masked_accuracy: 0.9834 - val_loss: 4.0069 - val_masked_accuracy: 0.6132\n",
      "Model: \"esbn_transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  42784     \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " decoder_2 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " esbn_encoder (ESBNEncoder)  multiple                  52323     \n",
      "                                                                 \n",
      " dense_27 (Dense)            multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,333\n",
      "Trainable params: 248,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "d_model = 32\n",
    "dff = 64\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "esbn_transformer = ESBNTransformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=command_vocab_len,\n",
    "    target_vocab_size=action_vocab_len,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "esbn_transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "log_dir = \"logs/fit/scan_transformer_esbn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "esbn_transformer.fit(train_ds,\n",
    "                epochs=20,\n",
    "                validation_data=val_ds,\n",
    "                callbacks=[tensorboard_callback])\n",
    "\n",
    "esbn_transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "458/458 [==============================] - 34s 57ms/step - loss: 0.7831 - masked_accuracy: 0.6858 - val_loss: 2.7328 - val_masked_accuracy: 0.4926\n",
      "Epoch 2/20\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.4942 - masked_accuracy: 0.7856 - val_loss: 2.9598 - val_masked_accuracy: 0.5116\n",
      "Epoch 3/20\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.3583 - masked_accuracy: 0.8456 - val_loss: 2.8594 - val_masked_accuracy: 0.5700\n",
      "Epoch 4/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.2245 - masked_accuracy: 0.9074 - val_loss: 2.8846 - val_masked_accuracy: 0.5834\n",
      "Epoch 5/20\n",
      "458/458 [==============================] - 26s 58ms/step - loss: 0.1597 - masked_accuracy: 0.9354 - val_loss: 2.9784 - val_masked_accuracy: 0.5838\n",
      "Epoch 6/20\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.1244 - masked_accuracy: 0.9509 - val_loss: 2.9334 - val_masked_accuracy: 0.6213\n",
      "Epoch 7/20\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.0991 - masked_accuracy: 0.9613 - val_loss: 2.9924 - val_masked_accuracy: 0.6113\n",
      "Epoch 8/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0848 - masked_accuracy: 0.9671 - val_loss: 2.9412 - val_masked_accuracy: 0.6293\n",
      "Epoch 9/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0724 - masked_accuracy: 0.9724 - val_loss: 2.8990 - val_masked_accuracy: 0.6389\n",
      "Epoch 10/20\n",
      "458/458 [==============================] - 27s 58ms/step - loss: 0.0661 - masked_accuracy: 0.9749 - val_loss: 3.3421 - val_masked_accuracy: 0.6251\n",
      "Epoch 11/20\n",
      "458/458 [==============================] - 26s 58ms/step - loss: 0.0609 - masked_accuracy: 0.9774 - val_loss: 3.1205 - val_masked_accuracy: 0.6043\n",
      "Epoch 12/20\n",
      "458/458 [==============================] - 26s 57ms/step - loss: 0.0530 - masked_accuracy: 0.9808 - val_loss: 3.4854 - val_masked_accuracy: 0.5921\n",
      "Epoch 13/20\n",
      "458/458 [==============================] - 28s 61ms/step - loss: 0.0476 - masked_accuracy: 0.9828 - val_loss: 3.2398 - val_masked_accuracy: 0.6198\n",
      "Epoch 14/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0434 - masked_accuracy: 0.9842 - val_loss: 3.5106 - val_masked_accuracy: 0.6030\n",
      "Epoch 15/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0463 - masked_accuracy: 0.9837 - val_loss: 3.4955 - val_masked_accuracy: 0.6152\n",
      "Epoch 16/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0379 - masked_accuracy: 0.9864 - val_loss: 3.5594 - val_masked_accuracy: 0.6320\n",
      "Epoch 17/20\n",
      "458/458 [==============================] - 29s 63ms/step - loss: 0.0351 - masked_accuracy: 0.9874 - val_loss: 2.8013 - val_masked_accuracy: 0.6384\n",
      "Epoch 18/20\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.0419 - masked_accuracy: 0.9853 - val_loss: 3.6814 - val_masked_accuracy: 0.6051\n",
      "Epoch 19/20\n",
      "458/458 [==============================] - 27s 59ms/step - loss: 0.0289 - masked_accuracy: 0.9898 - val_loss: 3.3041 - val_masked_accuracy: 0.6259\n",
      "Epoch 20/20\n",
      "458/458 [==============================] - 27s 60ms/step - loss: 0.0318 - masked_accuracy: 0.9889 - val_loss: 3.2735 - val_masked_accuracy: 0.6139\n",
      "Model: \"esbn_transformer_sca\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Encoder)         multiple                  42784     \n",
      "                                                                 \n",
      " decoder_3 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " decoder_4 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " esbn_encoder_cross_attentio  multiple                 52323     \n",
      " n (ESBNEncoderCrossAttentio                                     \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_46 (Dense)            multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,333\n",
      "Trainable params: 248,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "d_model = 32\n",
    "dff = 64\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "esbn_transformer_sca = ESBNTransformerSCA(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=command_vocab_len,\n",
    "    target_vocab_size=action_vocab_len,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "esbn_transformer_sca.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[masked_accuracy])\n",
    "\n",
    "log_dir = \"logs/fit/scan_transformer_esbn_sca/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "esbn_transformer_sca.fit(train_ds,\n",
    "                epochs=20,\n",
    "                validation_data=val_ds,\n",
    "                callbacks=[tensorboard_callback])\n",
    "\n",
    "esbn_transformer_sca.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"esbn_transformer_sca\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Encoder)         multiple                  42784     \n",
      "                                                                 \n",
      " decoder_3 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " decoder_4 (Decoder)         multiple                  76288     \n",
      "                                                                 \n",
      " esbn_encoder_cross_attentio  multiple                 52323     \n",
      " n (ESBNEncoderCrossAttentio                                     \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_46 (Dense)            multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,333\n",
      "Trainable params: 248,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "esbn_transformer_sca.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 58338), started 0:04:30 ago. (Use '!kill 58338' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-351f86c71cfd5055\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-351f86c71cfd5055\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
