{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 15:56:33.471407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from train_and_eval import train\n",
    "from create_task import *\n",
    "from ESBN_reimplementation import ESBN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import tensorboard\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we run the relevant code for replicating the original findings of (Webb 2021) and implementing a relational bottleneck as a seperate processing stream in deep language models.\n",
    "Firstly, we will run the training script for the replication and evaluate the performance of both the esbn, a transformer and the abstractor (Webb 2023).\n",
    "Secondly, we will integrate the abstractor and the esbn into a small language model and compare the performance with a transformer of similar size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment parameters\n",
    "m_holdout = 95\n",
    "n_shapes = 100\n",
    "y_dim = 4\n",
    "\n",
    "\n",
    "# Set train parameters\n",
    "batch_size = 32\n",
    "train_set_size = 360\n",
    "train_proportion = 0.95\n",
    "epochs = 150\n",
    "lr = 5e-4\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# Set test parameters\n",
    "test_batch_size = 100\n",
    "test_set_size = 100\n",
    "\n",
    "# Randomly assigns objects to training or test set\n",
    "all_shapes = np.arange(n_shapes)\n",
    "np.random.shuffle(all_shapes)\n",
    "if m_holdout > 0:\n",
    "    train_shapes = all_shapes[m_holdout:]\n",
    "    test_shapes = all_shapes[:m_holdout]\n",
    "else:\n",
    "    train_shapes = all_shapes\n",
    "    test_shapes = all_shapes\n",
    "\n",
    "\n",
    "# Generate training and test sets\n",
    "train_set, test_set = create_task(train_shapes, test_shapes, train_set_size, test_set_size, train_proportion, m_holdout, n_shapes)\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_set).batch(batch_size).prefetch(20)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_set).batch(batch_size).prefetch(20)\n",
    "\n",
    "# Load images\n",
    "all_imgs = []\n",
    "for i in range(n_shapes):\n",
    "    img_fname = \"../imgs/\" + str(i) + \".png\"\n",
    "    img = tf.convert_to_tensor(np.array(Image.open(img_fname)), dtype=tf.float32) / 255.\n",
    "    all_imgs.append(img)\n",
    "all_imgs = tf.stack(all_imgs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/12 [00:00<?, ?it/s]2024-02-23 15:57:00.730449: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [360]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "Epoch: 0: 100%|██████████| 12/12 [00:03<00:00,  3.93it/s]\n",
      "2024-02-23 15:57:03.789700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [100]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "Epoch: 1: 100%|██████████| 12/12 [00:02<00:00,  4.08it/s]\n",
      "Epoch: 2: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n",
      "Epoch: 3: 100%|██████████| 12/12 [00:03<00:00,  3.75it/s]\n",
      "Epoch: 4: 100%|██████████| 12/12 [00:02<00:00,  4.15it/s]\n",
      "Epoch: 5: 100%|██████████| 12/12 [00:02<00:00,  4.52it/s]\n",
      "Epoch: 6: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 7: 100%|██████████| 12/12 [00:02<00:00,  4.75it/s]\n",
      "Epoch: 8: 100%|██████████| 12/12 [00:02<00:00,  4.28it/s]\n",
      "Epoch: 9: 100%|██████████| 12/12 [00:03<00:00,  3.66it/s]\n",
      "Epoch: 10: 100%|██████████| 12/12 [00:02<00:00,  4.45it/s]\n",
      "Epoch: 11: 100%|██████████| 12/12 [00:03<00:00,  3.69it/s]\n",
      "Epoch: 12: 100%|██████████| 12/12 [00:02<00:00,  4.53it/s]\n",
      "Epoch: 13: 100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
      "Epoch: 14: 100%|██████████| 12/12 [00:02<00:00,  4.54it/s]\n",
      "Epoch: 15: 100%|██████████| 12/12 [00:02<00:00,  4.64it/s]\n",
      "Epoch: 16: 100%|██████████| 12/12 [00:02<00:00,  4.55it/s]\n",
      "Epoch: 17: 100%|██████████| 12/12 [00:02<00:00,  4.66it/s]\n",
      "Epoch: 18: 100%|██████████| 12/12 [00:02<00:00,  4.65it/s]\n",
      "Epoch: 19: 100%|██████████| 12/12 [00:02<00:00,  4.58it/s]\n",
      "Epoch: 20: 100%|██████████| 12/12 [00:02<00:00,  4.59it/s]\n",
      "Epoch: 21: 100%|██████████| 12/12 [00:02<00:00,  4.51it/s]\n",
      "Epoch: 22: 100%|██████████| 12/12 [00:02<00:00,  4.52it/s]\n",
      "Epoch: 23: 100%|██████████| 12/12 [00:02<00:00,  4.69it/s]\n",
      "Epoch: 24: 100%|██████████| 12/12 [00:02<00:00,  4.59it/s]\n",
      "Epoch: 25: 100%|██████████| 12/12 [00:02<00:00,  4.68it/s]\n",
      "Epoch: 26: 100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n",
      "Epoch: 27: 100%|██████████| 12/12 [00:02<00:00,  4.46it/s]\n",
      "Epoch: 28: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n",
      "Epoch: 29: 100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n",
      "Epoch: 30: 100%|██████████| 12/12 [00:02<00:00,  4.54it/s]\n",
      "Epoch: 31: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 32: 100%|██████████| 12/12 [00:02<00:00,  4.82it/s]\n",
      "Epoch: 33: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 34: 100%|██████████| 12/12 [00:02<00:00,  4.82it/s]\n",
      "Epoch: 35: 100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
      "Epoch: 36: 100%|██████████| 12/12 [00:02<00:00,  4.84it/s]\n",
      "Epoch: 37: 100%|██████████| 12/12 [00:02<00:00,  4.79it/s]\n",
      "Epoch: 38: 100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
      "Epoch: 39: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 40: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 41: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 42: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 43: 100%|██████████| 12/12 [00:02<00:00,  4.82it/s]\n",
      "Epoch: 44: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 45: 100%|██████████| 12/12 [00:02<00:00,  4.79it/s]\n",
      "Epoch: 46: 100%|██████████| 12/12 [00:02<00:00,  4.52it/s]\n",
      "Epoch: 47: 100%|██████████| 12/12 [00:02<00:00,  4.66it/s]\n",
      "Epoch: 48: 100%|██████████| 12/12 [00:02<00:00,  4.47it/s]\n",
      "Epoch: 49: 100%|██████████| 12/12 [00:02<00:00,  4.61it/s]\n",
      "Epoch: 50: 100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n",
      "Epoch: 51: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 52: 100%|██████████| 12/12 [00:02<00:00,  4.90it/s]\n",
      "Epoch: 53: 100%|██████████| 12/12 [00:02<00:00,  4.75it/s]\n",
      "Epoch: 54: 100%|██████████| 12/12 [00:02<00:00,  4.65it/s]\n",
      "Epoch: 55: 100%|██████████| 12/12 [00:02<00:00,  4.71it/s]\n",
      "Epoch: 56: 100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
      "Epoch: 57: 100%|██████████| 12/12 [00:02<00:00,  4.63it/s]\n",
      "Epoch: 58: 100%|██████████| 12/12 [00:02<00:00,  4.93it/s]\n",
      "Epoch: 59: 100%|██████████| 12/12 [00:02<00:00,  4.75it/s]\n",
      "Epoch: 60: 100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
      "Epoch: 61: 100%|██████████| 12/12 [00:02<00:00,  4.69it/s]\n",
      "Epoch: 62: 100%|██████████| 12/12 [00:02<00:00,  4.04it/s]\n",
      "Epoch: 63: 100%|██████████| 12/12 [00:02<00:00,  4.41it/s]\n",
      "Epoch: 64: 100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n",
      "Epoch: 65: 100%|██████████| 12/12 [00:02<00:00,  4.45it/s]\n",
      "Epoch: 66: 100%|██████████| 12/12 [00:02<00:00,  4.47it/s]\n",
      "Epoch: 67: 100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
      "Epoch: 68: 100%|██████████| 12/12 [00:02<00:00,  4.63it/s]\n",
      "Epoch: 69: 100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n",
      "Epoch: 70: 100%|██████████| 12/12 [00:02<00:00,  4.80it/s]\n",
      "Epoch: 71: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 72: 100%|██████████| 12/12 [00:02<00:00,  4.79it/s]\n",
      "Epoch: 73: 100%|██████████| 12/12 [00:02<00:00,  4.73it/s]\n",
      "Epoch: 74: 100%|██████████| 12/12 [00:02<00:00,  4.56it/s]\n",
      "Epoch: 75: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 76: 100%|██████████| 12/12 [00:02<00:00,  4.75it/s]\n",
      "Epoch: 77: 100%|██████████| 12/12 [00:02<00:00,  4.69it/s]\n",
      "Epoch: 78: 100%|██████████| 12/12 [00:02<00:00,  4.77it/s]\n",
      "Epoch: 79: 100%|██████████| 12/12 [00:02<00:00,  4.50it/s]\n",
      "Epoch: 80: 100%|██████████| 12/12 [00:02<00:00,  4.77it/s]\n",
      "Epoch: 81: 100%|██████████| 12/12 [00:02<00:00,  4.79it/s]\n",
      "Epoch: 82: 100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
      "Epoch: 83: 100%|██████████| 12/12 [00:02<00:00,  4.74it/s]\n",
      "Epoch: 84: 100%|██████████| 12/12 [00:02<00:00,  4.78it/s]\n",
      "Epoch: 85: 100%|██████████| 12/12 [00:02<00:00,  4.79it/s]\n",
      "Epoch: 86: 100%|██████████| 12/12 [00:02<00:00,  4.73it/s]\n",
      "Epoch: 87: 100%|██████████| 12/12 [00:02<00:00,  4.29it/s]\n",
      "Epoch: 88: 100%|██████████| 12/12 [00:03<00:00,  3.76it/s]\n",
      "Epoch: 89: 100%|██████████| 12/12 [00:02<00:00,  4.42it/s]\n",
      "Epoch: 90: 100%|██████████| 12/12 [00:03<00:00,  3.87it/s]\n",
      "Epoch: 91: 100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
      "Epoch: 92: 100%|██████████| 12/12 [00:02<00:00,  4.56it/s]\n",
      "Epoch: 93: 100%|██████████| 12/12 [00:02<00:00,  4.73it/s]\n",
      "Epoch: 94: 100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
      "Epoch: 95: 100%|██████████| 12/12 [00:02<00:00,  4.72it/s]\n",
      "Epoch: 96: 100%|██████████| 12/12 [00:02<00:00,  4.80it/s]\n",
      "Epoch: 97: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 98: 100%|██████████| 12/12 [00:02<00:00,  4.54it/s]\n",
      "Epoch: 99: 100%|██████████| 12/12 [00:02<00:00,  4.62it/s]\n",
      "Epoch: 100: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]\n",
      "Epoch: 101: 100%|██████████| 12/12 [00:02<00:00,  4.65it/s]\n",
      "Epoch: 102: 100%|██████████| 12/12 [00:02<00:00,  4.63it/s]\n",
      "Epoch: 103: 100%|██████████| 12/12 [00:02<00:00,  4.82it/s]\n",
      "Epoch: 104: 100%|██████████| 12/12 [00:02<00:00,  4.74it/s]\n",
      "Epoch: 105: 100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
      "Epoch: 106: 100%|██████████| 12/12 [00:02<00:00,  4.85it/s]\n",
      "Epoch: 107: 100%|██████████| 12/12 [00:02<00:00,  4.56it/s]\n",
      "Epoch: 108: 100%|██████████| 12/12 [00:02<00:00,  4.91it/s]\n",
      "Epoch: 109: 100%|██████████| 12/12 [00:02<00:00,  4.87it/s]\n",
      "Epoch: 110: 100%|██████████| 12/12 [00:02<00:00,  4.43it/s]\n",
      "Epoch: 111: 100%|██████████| 12/12 [00:02<00:00,  4.56it/s]\n",
      "Epoch: 112: 100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n",
      "Epoch: 113: 100%|██████████| 12/12 [00:02<00:00,  4.01it/s]\n",
      "Epoch: 114: 100%|██████████| 12/12 [00:02<00:00,  4.20it/s]\n",
      "Epoch: 115: 100%|██████████| 12/12 [00:02<00:00,  4.14it/s]\n",
      "Epoch: 116: 100%|██████████| 12/12 [00:02<00:00,  4.20it/s]\n",
      "Epoch: 117: 100%|██████████| 12/12 [00:02<00:00,  4.70it/s]\n",
      "Epoch: 118: 100%|██████████| 12/12 [00:02<00:00,  4.88it/s]\n",
      "Epoch: 119: 100%|██████████| 12/12 [00:02<00:00,  4.90it/s]\n",
      "Epoch: 120: 100%|██████████| 12/12 [00:02<00:00,  4.99it/s]\n",
      "Epoch: 121: 100%|██████████| 12/12 [00:02<00:00,  4.95it/s]\n",
      "Epoch: 122: 100%|██████████| 12/12 [00:02<00:00,  4.77it/s]\n",
      "Epoch: 123: 100%|██████████| 12/12 [00:02<00:00,  4.93it/s]\n",
      "Epoch: 124: 100%|██████████| 12/12 [00:02<00:00,  4.94it/s]\n",
      "Epoch: 125: 100%|██████████| 12/12 [00:02<00:00,  4.92it/s]\n",
      "Epoch: 126: 100%|██████████| 12/12 [00:02<00:00,  4.97it/s]\n",
      "Epoch: 127: 100%|██████████| 12/12 [00:02<00:00,  4.97it/s]\n",
      "Epoch: 128: 100%|██████████| 12/12 [00:02<00:00,  4.91it/s]\n",
      "Epoch: 129: 100%|██████████| 12/12 [00:02<00:00,  4.90it/s]\n",
      "Epoch: 130: 100%|██████████| 12/12 [00:02<00:00,  4.78it/s]\n",
      "Epoch: 131: 100%|██████████| 12/12 [00:02<00:00,  4.85it/s]\n",
      "Epoch: 132: 100%|██████████| 12/12 [00:02<00:00,  4.74it/s]\n",
      "Epoch: 133: 100%|██████████| 12/12 [00:02<00:00,  4.93it/s]\n",
      "Epoch: 134: 100%|██████████| 12/12 [00:02<00:00,  4.92it/s]\n",
      "Epoch: 135: 100%|██████████| 12/12 [00:02<00:00,  4.77it/s]\n",
      "Epoch: 136: 100%|██████████| 12/12 [00:02<00:00,  4.92it/s]\n",
      "Epoch: 137: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]\n",
      "Epoch: 138: 100%|██████████| 12/12 [00:02<00:00,  4.97it/s]\n",
      "Epoch: 139: 100%|██████████| 12/12 [00:02<00:00,  4.90it/s]\n",
      "Epoch: 140: 100%|██████████| 12/12 [00:02<00:00,  4.97it/s]\n",
      "Epoch: 141: 100%|██████████| 12/12 [00:02<00:00,  4.97it/s]\n",
      "Epoch: 142: 100%|██████████| 12/12 [00:02<00:00,  4.62it/s]\n",
      "Epoch: 143: 100%|██████████| 12/12 [00:02<00:00,  4.64it/s]\n",
      "Epoch: 144: 100%|██████████| 12/12 [00:02<00:00,  4.66it/s]\n",
      "Epoch: 145: 100%|██████████| 12/12 [00:02<00:00,  4.87it/s]\n",
      "Epoch: 146: 100%|██████████| 12/12 [00:02<00:00,  4.69it/s]\n",
      "Epoch: 147: 100%|██████████| 12/12 [00:02<00:00,  4.70it/s]\n",
      "Epoch: 148: 100%|██████████| 12/12 [00:02<00:00,  4.55it/s]\n",
      "Epoch: 149: 100%|██████████| 12/12 [00:02<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = ESBN(y_dim)\n",
    "\n",
    "train(model, train_data, test_data, all_imgs, optimizer, loss_fn, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iannwtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
